{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hobohm 1\n",
    "\n",
    "### Fill in the blanked out part of the code (XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE THE PATH TO YOUR COURSE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/vinde/OneDrive/Dokumenter/DTU/Algorithms_in_bioinformatics/Project/Cluster_data/\"\n",
    "data_dir_2 = \"C:/Users/vinde/OneDrive/Dokumenter/DTU/Algorithms_in_bioinformatics/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_file = data_dir_2 + \"Matrices/alphabet\"\n",
    "alphabet = np.loadtxt(alphabet_file, dtype=str)\n",
    "\n",
    "alphabet\n",
    "\n",
    "blosum_file = data_dir_2 + \"Matrices/BLOSUM50\"\n",
    "_blosum50 = np.loadtxt(blosum_file, dtype=int).T\n",
    "\n",
    "blosum50 = {}\n",
    "\n",
    "for i, letter_1 in enumerate(alphabet):\n",
    "    \n",
    "    blosum50[letter_1] = {}\n",
    "\n",
    "    for j, letter_2 in enumerate(alphabet):\n",
    "        \n",
    "        blosum50[letter_1][letter_2] = _blosum50[i, j]\n",
    "        \n",
    "#blosum50      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences():\n",
    "    \n",
    "    #database_file = data_dir_2 + \"Hobohm/database_list.tab\"\n",
    "    #database_list = np.loadtxt(database_file, dtype=str).reshape(-1,2)\n",
    "\n",
    "    database_file = data_dir + \"A0201.txt\"\n",
    "    database_list = np.loadtxt(database_file, dtype=str).reshape(-1,2)\n",
    "    \n",
    "    #ids = database_list[:, 0]\n",
    "    #sequences = database_list[:, 1]\n",
    "\n",
    "    ids = database_list[:, 0]\n",
    "    sequences = database_list[:, 0]\n",
    "\n",
    "    return sequences, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smith-Waterman O2\n",
    "\n",
    "### This code is identical to the code you wrote the other day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smith_waterman(query, database, scoring_scheme, gap_open, gap_extension):\n",
    "    \n",
    "    P_matrix, Q_matrix, D_matrix, E_matrix, i_max, j_max, max_score = smith_waterman_alignment(query, database, scoring_scheme, gap_open, gap_extension)\n",
    "    \n",
    "    aligned_query, aligned_database, matches = smith_waterman_traceback(E_matrix, D_matrix, i_max, j_max, query, database, gap_open, gap_extension)\n",
    "    \n",
    "    return aligned_query, aligned_database, matches\n",
    "\n",
    "\n",
    "def smith_waterman_alignment(query, database, scoring_scheme, gap_open, gap_extension):\n",
    "\n",
    "    # Matrix imensions\n",
    "    M = len(query)\n",
    "    N = len(database)\n",
    "    \n",
    "    # D matrix change to float\n",
    "    D_matrix = np.zeros((M+1, N+1), np.int)\n",
    "\n",
    "    # P matrix\n",
    "    P_matrix = np.zeros((M+1, N+1), np.int)\n",
    "    \n",
    "    # Q matrix\n",
    "    Q_matrix = np.zeros((M+1, N+1), np.int)\n",
    "\n",
    "    # E matrix\n",
    "    E_matrix = np.zeros((M+1, N+1), dtype=object)\n",
    "\n",
    "    # Main loop\n",
    "    D_matrix_max_score, D_matrix_i_max, D_matrix_i_max = -9, -9, -9\n",
    "    for i in range(M-1, -1, -1):\n",
    "        for j in range(N-1, -1, -1):\n",
    "            \n",
    "            # Q_matrix[i,j] entry\n",
    "            gap_open_database = D_matrix[i+1,j] + gap_open\n",
    "            gap_extension_database = Q_matrix[i+1,j] + gap_extension\n",
    "            max_gap_database = max(gap_open_database, gap_extension_database)\n",
    "            \n",
    "            Q_matrix[i,j] = max_gap_database\n",
    "                \n",
    "            # P_matrix[i,j] entry\n",
    "            gap_open_query = D_matrix[i,j+1] + gap_open\n",
    "            gap_extension_query = P_matrix[i,j+1] + gap_extension\n",
    "            max_gap_query = max(gap_open_query, gap_extension_query)\n",
    "            \n",
    "            P_matrix[i,j] = max_gap_query\n",
    "            \n",
    "            # D_matrix[i,j] entry\n",
    "            diagonal_score = D_matrix[i+1,j+1] + scoring_scheme[query[i]][database[j]]    \n",
    "            \n",
    "            # E_matrix[i,j] entry\n",
    "            candidates = [(1, diagonal_score),\n",
    "                          (2, gap_open_database),\n",
    "                          (4, gap_open_query),\n",
    "                          (3, gap_extension_database),\n",
    "                          (5, gap_extension_query)]\n",
    "            \n",
    "            direction, max_score = max(candidates, key=lambda x: x[1])\n",
    "            \n",
    "            \n",
    "            # check entry sign\n",
    "            if max_score > 0:\n",
    "                E_matrix[i,j] = direction\n",
    "            else:\n",
    "                E_matrix[i,j] = 0\n",
    "            \n",
    "            # check max score sign\n",
    "            if max_score > 0:\n",
    "                D_matrix[i, j] = max_score\n",
    "            else:\n",
    "                D_matrix[i, j] = 0\n",
    "\n",
    "            # fetch global max score\n",
    "            if max_score > D_matrix_max_score:\n",
    "                D_matrix_max_score = max_score\n",
    "                D_matrix_i_max = i\n",
    "                D_matrix_j_max = j\n",
    "            \n",
    "    return P_matrix, Q_matrix, D_matrix, E_matrix, D_matrix_i_max, D_matrix_j_max, D_matrix_max_score\n",
    "\n",
    "\n",
    "def smith_waterman_traceback(E_matrix, D_matrix, i_max, j_max, query, database, gap_open, gap_extension):\n",
    "    \n",
    "    # Matrix imensions\n",
    "    M = len(query)\n",
    "    N = len(database)\n",
    "    \n",
    "    # aligned query string\n",
    "    aligned_query = []\n",
    "    \n",
    "    # aligned database string\n",
    "    aligned_database = []\n",
    "    \n",
    "    # total identical matches\n",
    "    matches = 0\n",
    "\n",
    "        \n",
    "    # start from max_i, max_j\n",
    "    i, j = i_max, j_max\n",
    "    while i < M and j < N:\n",
    "\n",
    "        # E[i,j] = 0, stop back tracking\n",
    "        if E_matrix[i, j] == 0:\n",
    "            break\n",
    "        \n",
    "        # E[i,j] = 1, match\n",
    "        if E_matrix[i, j] == 1:\n",
    "            aligned_query.append(query[i])\n",
    "            aligned_database.append(database[j])\n",
    "            if ( query[i] == database[j]):\n",
    "                matches += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        \n",
    "        \n",
    "        # E[i,j] = 2, gap opening in database\n",
    "        if E_matrix[i, j] == 2:\n",
    "            aligned_database.append(\"-\")\n",
    "            aligned_query.append(query[i])\n",
    "            i += 1\n",
    "\n",
    "            \n",
    "        # E[i,j] = 3, gap extension in database\n",
    "        if E_matrix[i, j] == 3:\n",
    "                   \n",
    "            count = i + 2\n",
    "            score = D_matrix[count, j] + gap_open + gap_extension\n",
    "            \n",
    "            # Find length of gap\n",
    "            while((score - D_matrix[i, j])*(score - D_matrix[i, j]) >= 0.00001):   \n",
    "                count += 1\n",
    "                score = D_matrix[count, j] + gap_open + (count-i-1)*gap_extension\n",
    "\n",
    "            for k in range(i, count):\n",
    "                aligned_database.append(\"-\")\n",
    "                aligned_query.append(query[i])\n",
    "                i += 1\n",
    "            \n",
    "            \n",
    "        # E[i,j] = 4, gap opening in query\n",
    "        if E_matrix[i, j] == 4:\n",
    "            aligned_query.append(\"-\")\n",
    "            aligned_database.append(database[j])\n",
    "            j += 1\n",
    "        \n",
    "        \n",
    "        # E[i,j] = 5, gap extension in query\n",
    "        if E_matrix[i, j] == 5:\n",
    "             \n",
    "            count = j + 2\n",
    "            score = D_matrix[i, count] + gap_open + gap_extension\n",
    "            \n",
    "            # Find length of gap\n",
    "            while((score - D_matrix[i, j])*(score - D_matrix[i, j]) >= 0.0001): \n",
    "                count += 1\n",
    "                score = D_matrix[i, count] + gap_open + (count-j-1)*gap_extension\n",
    "\n",
    "            for k in range(j, count):\n",
    "                aligned_query.append(\"-\")\n",
    "                aligned_database.append(database[j])\n",
    "                j += 1\n",
    "\n",
    "                \n",
    "    return aligned_query, aligned_database, matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hobohm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Function\n",
    "\n",
    "### This code defines the threshold for similarity\n",
    "\n",
    "### Homology score for 9-mer peptides: mismatch > 2/9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homology_function(alignment_length, matches):\n",
    "    \n",
    "    homology_score = 7\n",
    "    #homology_score = XX, this was just Ole's formula\n",
    "    #homology_score = 2.9*np.sqrt(alignment_length)**0.5\n",
    "    \n",
    "    #if matches XX homology_score: ## Add the inequally sign\n",
    "    if matches > homology_score:\n",
    "        return \"discard\", homology_score\n",
    "    else:\n",
    "        return \"keep\", homology_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Numner of elements: 3089\n",
      "# Unique. 0 0 YVMTMILFL\n"
     ]
    }
   ],
   "source": [
    "# load list\n",
    "candidate_sequences, candidate_ids = load_sequences()\n",
    "print (\"# Numner of elements:\", len(candidate_sequences))\n",
    "\n",
    "accepted_sequences, accepted_ids = [], []\n",
    "\n",
    "accepted_sequences.append(candidate_sequences[0])\n",
    "accepted_ids.append([candidate_ids[0]])\n",
    "#print(accepted_ids)\n",
    "print(\"# Unique.\", 0, len(accepted_sequences)-1, accepted_ids[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique. 1 1 YTYSGLFCV 7\n",
      "# Unique. 2 2 YQSFLFWFL 7\n",
      "# Unique. 3 3 YMMGIEYGL 7\n",
      "# Unique. 4 4 YLYALYSPL 7\n",
      "# Unique. 5 5 YLSSWTPVV 7\n",
      "# Unique. 6 6 YLSAKVYML 7\n",
      "# Unique. 7 7 YLMPYSVYI 7\n",
      "# Unique. 8 8 YLMDKLNLT 7\n",
      "# Unique. 9 9 YLLFNHFSV 7\n",
      "# Unique. 10 10 YLFGGFSTL 7\n",
      "# Unique. 11 11 YLDFLLLLL 7\n",
      "# Unique. 12 12 YITALNHLV 7\n",
      "# Unique. 13 13 YILCNMALL 7\n",
      "# Unique. 14 14 YIIDWMVDI 7\n",
      "# Unique. 15 15 WLYGYNFII 7\n",
      "# Unique. 16 16 WLIGFDFDV 7\n",
      "# Unique. 17 17 VMYAFTTPL 7\n",
      "# Unique. 18 18 VLLTYFCFV 7\n",
      "# Unique. 19 19 VLDTTLYAV 7\n",
      "# Unique. 20 20 VLALYSPPL 7\n",
      "# Unique. 21 21 TLYDFDYYI 7\n",
      "# Unique. 22 22 TLLGLILFV 7\n",
      "# Unique. 23 23 TLIDIWFLA 7\n",
      "# Unique. 24 24 TLAPFNFLV 7\n",
      "# Unique. 25 25 SMSSYDFST 7\n",
      "# Unique. 26 26 SLQEEIAFL 7\n",
      "# Unique. 27 27 SLLYLILFL 7\n",
      "# Unique. 28 28 SLDVINYLI 7\n",
      "# Unique. 29 29 SLAGGIIGV 7\n",
      "# Unique. 30 30 SIFGFQAEV 7\n",
      "# Unique. 31 31 RTFHIFYYL 7\n",
      "# Unique. 32 32 RQIFIHYSV 7\n",
      "# Unique. 33 33 RLVDFFPDI 7\n",
      "# Unique. 34 34 RLFSYNFTT 7\n",
      "# Unique. 35 35 RLAVYIDKV 7\n",
      "# Unique. 36 36 RILPYTFKI 7\n",
      "# Unique. 37 37 QLLDVKLAL 7\n",
      "# Unique. 38 38 NVFKYLTSV 7\n",
      "# Unique. 39 39 NLLLWPLYV 7\n",
      "# Unique. 40 40 MTFGDIPLV 7\n",
      "# Unique. 41 41 MLNGIMYRL 7\n",
      "# Unique. 42 42 MLMFIFTGI 7\n",
      "# Unique. 43 43 MLMEVFPQL 7\n",
      "# Unique. 44 44 MLLALVALV 7\n",
      "# Unique. 45 45 MLDDFSAGA 7\n",
      "# Unique. 46 46 LMSTLLIYL 7\n",
      "# Unique. 47 47 LMIFISSFL 7\n",
      "# Unique. 48 48 LMDSIFVST 7\n",
      "# Unique. 49 49 LLSKNTFYL 7\n",
      "# Unique. 50 50 LLSAINFKI 7\n",
      "# Unique. 51 51 LLNLLLWPL 7\n",
      "# Unique. 52 52 LLMMTLPSI 7\n",
      "# Not unique. 53 LLLWPLYVL is homolog to NLLLWPLYV 7\n",
      "# Unique. 54 53 LIMYSVIGV 7\n",
      "# Unique. 55 54 KVYDKLFPV 7\n",
      "# Unique. 56 55 KVIQYLAYV 7\n",
      "# Unique. 57 56 KTMAVTYEL 7\n",
      "# Unique. 58 57 KLGNLLLLI 7\n",
      "# Unique. 59 58 KLFYVYYNL 7\n",
      "# Unique. 60 59 KIDYYIPYV 7\n",
      "# Unique. 61 60 ILYDNVVTL 7\n",
      "# Unique. 62 61 ILQYDLWNV 7\n",
      "# Unique. 63 62 ILPVIFLSI 7\n",
      "# Unique. 64 63 ILASIIDYV 7\n",
      "# Unique. 65 64 HLMFYTLPI 7\n",
      "# Unique. 66 65 GLYSSTVPV 7\n",
      "# Unique. 67 66 GLLRVISGV 7\n",
      "# Unique. 68 67 GLLDRLYDL 7\n",
      "# Unique. 69 68 GLFDFVNFV 7\n",
      "# Unique. 70 69 FVFRSPFIV 7\n",
      "# Unique. 71 70 FVFAWFNGV 7\n",
      "# Unique. 72 71 FTSSFYNYV 7\n",
      "# Not unique. 73 FTLIDIWFL is homolog to TLIDIWFLA 7\n",
      "# Unique. 74 72 FLSYISDTV 7\n",
      "# Unique. 75 73 FLSRVFFCV 7\n",
      "# Unique. 76 74 FLSRLVLYA 7\n",
      "# Unique. 77 75 FLSNGHVTI 7\n",
      "# Unique. 78 76 FLSHHFTLV 7\n",
      "# Not unique. 79 FLSHDFTLV is homolog to FLSHHFTLV 7\n",
      "# Unique. 80 77 FLNISWFYI 7\n",
      "# Unique. 81 78 FLLPLTSLV 7\n",
      "# Unique. 82 79 FLIPKGFYA 7\n",
      "# Unique. 83 80 FLIDLAFLI 7\n",
      "# Unique. 84 81 FLHTTFIDV 7\n",
      "# Unique. 85 82 FLHNYILYA 7\n",
      "# Unique. 86 83 FLFFATSDV 7\n",
      "# Unique. 87 84 FLDNECHTI 7\n",
      "# Unique. 88 85 FLAVLSPTI 7\n",
      "# Unique. 89 86 FLAIKLYGV 7\n",
      "# Unique. 90 87 FILHRLHEI 7\n",
      "# Unique. 91 88 FILGIIITV 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-738b5b2452b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdatabase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccepted_sequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0maligned_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maligned_database\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmith_waterman\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_scheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_extension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0malignment_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maligned_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-32b3f90cabba>\u001b[0m in \u001b[0;36msmith_waterman\u001b[1;34m(query, database, scoring_scheme, gap_open, gap_extension)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msmith_waterman\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_scheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_extension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mP_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmith_waterman_alignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_scheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_extension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maligned_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maligned_database\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmith_waterman_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_extension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-32b3f90cabba>\u001b[0m in \u001b[0;36msmith_waterman_alignment\u001b[1;34m(query, database, scoring_scheme, gap_open, gap_extension)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m# Q_matrix[i,j] entry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mgap_open_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgap_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mgap_extension_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgap_extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mmax_gap_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgap_open_database\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap_extension_database\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "scoring_scheme = blosum50\n",
    "gap_open = -11\n",
    "gap_extension = -1\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "for i in range(1, len(candidate_sequences)):\n",
    "#for i in range(1, 41):\n",
    "\n",
    "    for j in range(0, len(accepted_sequences)):\n",
    "\n",
    "        query = candidate_sequences[i]\n",
    "        database = accepted_sequences[j] \n",
    "        \n",
    "        aligned_query, aligned_database, matches = smith_waterman(query, database, scoring_scheme, gap_open, gap_extension)\n",
    "        \n",
    "        alignment_length = len(aligned_query)\n",
    "        \n",
    "        homology_outcome, homology_score = homology_function(alignment_length, matches)\n",
    "     \n",
    "        # query is not unique\n",
    "        if homology_outcome == \"discard\":\n",
    "            \n",
    "            accepted_ids[j].append(candidate_ids[i])\n",
    "            print (\"# Not unique.\", i, candidate_ids[i], \"is homolog to\", accepted_ids[j][0], homology_score)\n",
    "            \n",
    "            break\n",
    "            \n",
    "            \n",
    "    # query is unique\n",
    "    if homology_outcome == \"keep\":\n",
    "        #accepted_sequences.append(XX)\n",
    "        accepted_sequences.append(candidate_sequences[i])\n",
    "        #accepted_ids.append(XX)\n",
    "        accepted_ids.append([candidate_ids[i]])\n",
    "\n",
    "        print (\"# Unique.\", i, len(accepted_sequences)-1, candidate_ids[i], homology_score)\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "print(\"Elapsed time (m):\", (t1-t0)/60)\n",
    "\n",
    "print (\"Accepted clusters:\", len(accepted_ids))\n",
    "for i in range(len(accepted_ids)):\n",
    "    print( accepted_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (m): -31.348621559143066\n",
      "Accepted clusters: 1\n",
      "['YQSFLFWFL;1.0']\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time (m):\", (t1-t0)/60)\n",
    "\n",
    "print (\"Accepted clusters:\", len(accepted_ids))\n",
    "for i in range(len(accepted_ids)):\n",
    "    print( accepted_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
